# 博物馆新闻采集分析子系统

## 1. 导言

### 1.1 目的

该文档的目的是描述子系统的用户使用说明，其主要内容包括：
- 运行环境
- 安装与配置
- 操作说明

本文档的预期的读者是：
- 用户
- 前端使用接口的开发人员

### 1.2 范围

该文档定义了系统提交产品的使用说明，主要描述了产品的操作流程，以及配置说明。

### 1.3 缩写说明

- UML (Unified Modeling Language)
	
	UML(统一建模语言)是一种用于指定、可视化、构造和记录软件系统工件的标准语言。

- Scrapy
	
	- Scrapy 是用 Python 实现的一个为了爬取网站数据、提取结构性数据而编写的应用框架。
	- Scrapy 常应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
	- 通常我们可以很简单的通过 Scrapy 框架实现一个爬虫，抓取指定网站的内容或图片。

- sklearn
	
	Scikit-learn（也称为sklearn）是Python编程语言的免费软件机器学习库。它具有各种分类、回归和聚类算法，包括支持向量机、随机林、梯度提升、k-均值和DBSCAN，旨在与 Python 数值和科学库NumPy和SciPy进行互操作。

- jieba

    一个python的中文分词组件包

### 1.4 术语定义

- 爬虫
	
	网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。


- 机器学习
	
	机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
	它是人工智能的核心，是使计算机具有智能的根本途径。

- 文本分析
	
	文本分析是对文本进行解析，以便从中提取机器可读的事实。文本分析的目的是用自由文本内容创建结构化数据。这个过程可以看作是将一堆非结构化、异构的文档分割成易于管理和解释的数据块。

### 1.5 参考资料

- python参考资料：
	- [https://github.com/wistbean/learn_python3_spider](https://github.com/wistbean/learn_python3_spider)
	- [https://www.runoob.com/w3cnote/python-spider-intro.html](https://www.runoob.com/w3cnote/python-spider-intro.html)

- 《Python网络数据采集》

- Scrapy文档 
	- [Scrapy官方文档](https://docs.scrapy.org/en/latest/intro/tutorial.html)
	- [Scrapy教程](https://www.runoob.com/w3cnote/scrapy-detail.html)

- 机器学习
	- [sklearn官方文档](https://sklearn.apachecn.org/)

- jieba官方文档
    - [结巴官方文档](https://github.com/fxsjy/jieba)

## 2. 概述

该子系统是一个对数据进行获取、处理和分析的子系统，它使用了Scrapy框架技术，可运行在本地PC或Ubuntu服务器上，数据库系统为MySQL。此系统分为爬虫项目和服务端两部分，服务端为前端提供一个接口实现数据定制服务，可以获取指定博物馆在指定时间的正面或负面新闻。爬虫项目可以实现从网络爬取有关博物馆的新闻，从中提取中新闻的标题、时间、作者、有关博物馆以及新闻正负等信息。册

第三章介绍系统的运行环境，第四章介绍系统的安装与配置，第五章介绍系统的操作流程说明。

## 3. 运行环境

### 3.1 系统运行硬件环境

- 服务器
  - 配置信息
    - 操作系统
      - Ubuntu Server 18.04 1 LTS 64位
    - CPU
      - 1核
    - 内存
      - 2GB
    - 带宽
      - 1Mbps
  
- 客户机：普通PC

### 3.2 系统运行软件环境
- 操作系统
  - Win10/Macos/Linux
- 数据库
  - MySQL 或其他数据库操作软件
- 浏览器
  - Microsoft Edge/Google Chrome

## 4. 安装与配置

### 4.1 爬虫项目

- scrapy模块

```shell
# 安装方式
pip install scrapy
```

- jieba模块

```shell
# 安装方式
pip install jieba
```

- 百度aip文本分析接口

```shell
# 安装方式
pip install baidu-aip
```

- pymysql

```shell
# 安装方式
pip install pymysql
```

- pandas

```shell
# 安装方式
pip install pandas
```

### 4.2 服务器接口项目

接口部分由get_new_info.js接口实现。该接口集成在后台管理子系统中，具体安装配置详见后台程序安装配置部分。


## 5. 操作说明

### 5.1 爬虫项目

> 运行目录：
  本地运行时在museum_news_spider项目根目录中执行以下指令
  服务器运行时直接在任意pc任意终端命令行输入命令即可

#### 5.1.1 newspider.py爬虫

- 该爬虫用来从网页爬取新闻

- 本地运行：
  - `scrapy crawl newspider` :默认输入爬取的是 **博物馆** 新闻 在所有时间范围内
  - `scrapy crawl newspider -a startTime=2020-05-17 -a endTime=2020-05-18`：爬取的是 **博物馆** 在指定时间内的新闻
  - `scrapy crawl newspider -a museum=故宫博物馆`：爬取的是 **故宫博物馆** 在所有时间范围的新闻
  - `scrapy crawl newspider -a museum=故宫博物馆 -a startTime=2020-05-17 -a endTime=2020-05-18`: 爬取的是 **故宫博物馆** 在指定时间范围内的新闻

- 服务器运行
  - `curl http://192.144.239.176:6800/schedule.json -d project=museum_news_spider -d spider=newspider` :默认输入爬取的是 **博物馆** 新闻 在所有时间范围内
  - `curl http://192.144.239.176:6800/schedule.json -d project=museum_news_spider -d spider=newspider -d startTime=2020-05-17 -d endTime=2020-05-18`：爬取的是 **博物馆** 在指定时间内的新闻
  - `curl http://192.144.239.176:6800/schedule.json -d project=museum_news_spider -d spider=newspider -d museum=故宫博物馆`：爬取的是 **故宫博物馆** 在所有时间范围的新闻
  - `curl http://192.144.239.176:6800/schedule.json -d project=museum_news_spider -d spider=newspider -d museum=故宫博物馆 -d startTime=2020-05-17 -d endTime=2020-05-18`: 爬取的是 **故宫博物馆** 在指定时间范围内的新闻

> 运行时参数为 `museum  startTime  endTime`不要写错，博物馆名称不用加引号，时间格式为：`%Y-%m-%d`

> startTime和endTime可以指定其中一个，也可以全部指定

#### 5.1.2 NewsTest.py爬虫

- 该爬虫用来提取新闻原文，从中筛选出与该新闻有关的博物馆，同时进行新闻文本分析

- 本地运行：
  - `scrapy crawl NewsTest`: 从数据库中取出新闻原文，并进行文本分析
  - `scrapy crawl -o output.json`: 从数据库中取出新闻原文进行文本分析，将结果输出到output.json文件中

- 服务器运行
  - `curl http://192.144.239.176:6800/schedule.json -d project=museum_news_spider -d spider=NewsTest`: 从数据库中取出新闻原文，并进行文本分析
  

### 5.1.3 服务器爬虫项目操作（仅供开发人员参考）

  - `curl http://192.144.239.176:6800/listjobs.json?project=museum_news_spider`: 获取服务器上**museum_news_spider**项目中正在运行的爬虫信息
  - `curl http://192.144.239.176:6800/cancel.json -d project=museum_news_spider -d job=8c9f5d769b8711eaab2a5254000fd2ba`: 停止服务器中**museum_news_spider**项目中id为**8c9f5d769b8711eaab2a5254000fd2ba**的爬虫
  - `curl http://192.144.239.176:6800/listspiders.json?project=museum_news_spider`: 获取服务器上**museum_news_spider**中的所有爬虫项目名称
  - `curl http://192.144.239.176:6800/delete.json -d project=MuseumNews`: 删除服务器上名字为**museum_news_spider**中的爬虫项目

### 5.2 接口调用

- 浏览器输入或postman请求：`http://192.144.239.176:8080/api/group2/get_new_info?id=1&start_date=2000-10-01&end_date=2020-05-21&tag=2&page=1&ppn=1000`
    - id代表数据库中博物馆的id
    - start_date与end_date为日期
    - tag为新闻的正负，0代表负面，1代表中性，2代表正面
    - ppn代表分页请求时每页的新闻条数，默认为10
    - page代表分页式显示信息的页数，默认为1
    - 所有参数均为可选参数